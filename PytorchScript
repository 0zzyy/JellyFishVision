
import torch
import torch.nn as nn
import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
from timm import create_model
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split
from pytorch_metric_learning import losses, miners
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2
import numpy as np
from pathlib import Path
import os

class CBAM(nn.Module):
    def __init__(self, channels, reduction_ratio=16):
        super().__init__()
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1), nn.Conv2d(channels, channels // reduction_ratio, 1),
            nn.ReLU(), nn.Conv2d(channels // reduction_ratio, channels, 1), nn.Sigmoid()
        )
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(2, 1, kernel_size=7, padding=3), nn.Sigmoid()
        )

    def forward(self, x):
        x = x * self.channel_attention(x)
        return x * self.spatial_attention(torch.cat([
            torch.max(x, dim=1, keepdim=True)[0],
            torch.mean(x, dim=1, keepdim=True)
        ], dim=1))

class CustomEfficientNetB7(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.efficientnet = create_model('efficientnet_b7', pretrained=True, num_classes=0)
        self.cbam = CBAM(self.efficientnet.num_features)
        self.classifier = nn.Linear(self.efficientnet.num_features, num_classes)
        self.underwater_conv = nn.Conv2d(3, 3, kernel_size=3, padding=1)
        self.beach_conv = nn.Conv2d(3, 3, kernel_size=3, padding=1)
        self.attention = nn.Sequential(
            nn.Conv2d(3, 1, kernel_size=1),
            nn.Sigmoid()
        )

    def forward(self, x):
        attention = self.attention(x)
        x_underwater = self.underwater_conv(x * attention)
        x_beach = self.beach_conv(x * (1 - attention))
        x = x_underwater + x_beach
        x = self.efficientnet.forward_features(x)
        x = self.cbam(x)
        x = self.efficientnet.global_pool(x)
        x = x.flatten(1)
        return self.classifier(x)

class JellyfishDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths, self.labels, self.transform = image_paths, labels, transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = str(self.image_paths[idx])
        try:
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"Failed to load image: {image_path}")
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            if self.transform:
                image = self.transform(image=image)["image"]
            return image, self.labels[idx]
        except Exception as e:
            print(f"Error loading image {image_path}: {str(e)}")
            return None

class JellyfishModel(pl.LightningModule):
    def __init__(self, num_classes, learning_rate=1e-3):
        super().__init__()
        self.model = CustomEfficientNetB7(num_classes)
        self.criterion = nn.CrossEntropyLoss()
        self.metric_loss = losses.ArcFaceLoss(num_classes, self.model.efficientnet.num_features)
        self.miner = miners.MultiSimilarityMiner()
        self.learning_rate = learning_rate

    def forward(self, x):
        return self.model(x)

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = self.criterion(logits, y) + self.metric_loss(logits, y, self.miner(logits, y))
        self.log('train_loss', loss)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = self.criterion(logits, y)
        acc = (logits.argmax(dim=1) == y).float().mean()
        self.log('val_loss', loss)
        self.log('val_acc', acc)
        return {'val_loss': loss, 'val_acc': acc, 'logits': logits, 'y': y}

    def configure_optimizers(self):
        optimizer = AdamW(self.parameters(), lr=self.learning_rate)
        scheduler = CosineAnnealingLR(optimizer, T_max=10)
        return [optimizer], [scheduler]

def underwater_effect(img):
    blue_channel = img[:, :, 0]
    blue_channel = cv2.GaussianBlur(blue_channel, (5, 5), 0)
    img[:, :, 0] = blue_channel
    return img

def beach_effect(img):
    brightness = np.random.uniform(1.0, 1.5)
    contrast = np.random.uniform(0.8, 1.2)
    img = cv2.convertScaleAbs(img, alpha=contrast, beta=brightness)
    return img

class UnderwaterEffect(A.ImageOnlyTransform):
    def __init__(self, always_apply=False, p=0.5):
        super().__init__(always_apply, p)

    def apply(self, img, **params):
        return underwater_effect(img)

class BeachEffect(A.ImageOnlyTransform):
    def __init__(self, always_apply=False, p=0.5):
        super().__init__(always_apply, p)

    def apply(self, img, **params):
        return beach_effect(img)

def get_transforms(is_train=True):
    if is_train:
        return A.Compose([
            A.RandomRotate90(),
            A.Flip(),
            A.Transpose(),
            UnderwaterEffect(p=0.5),
            BeachEffect(p=0.5),
            A.OneOf([
                A.IAAAdditiveGaussianNoise(),
                A.GaussNoise(),
            ], p=0.2),
            A.OneOf([
                A.MotionBlur(p=0.2),
                A.MedianBlur(blur_limit=3, p=0.1),
                A.Blur(blur_limit=3, p=0.1),
            ], p=0.2),
            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),
            A.OneOf([
                A.OpticalDistortion(p=0.3),
                A.GridDistortion(p=0.1),
                A.IAAPiecewiseAffine(p=0.3),
            ], p=0.2),
            A.OneOf([
                A.CLAHE(clip_limit=2),
                A.IAASharpen(),
                A.IAAEmboss(),
                A.RandomBrightnessContrast(),
            ], p=0.3),
            A.HueSaturationValue(p=0.3),
            A.Normalize(),
            ToTensorV2(),
        ])
    else:
        return A.Compose([
            A.Normalize(),
            ToTensorV2(),
        ])

def main():
    # Set the data directory to access Windows files from WSL2
    windows_path = "/Users/iliad/Desktop/tf/images/train"
    wsl_path = f"/mnt/c{windows_path}"
    data_dir = Path(wsl_path)
    
    # Check if the directory exists
    if not data_dir.exists():
        print(f"Error: Directory {data_dir} does not exist.")
        return

    image_paths = list(data_dir.glob("**/*.jpg")) + list(data_dir.glob("**/*.jpeg")) + list(data_dir.glob("**/*.png"))
    
    if not image_paths:
        print(f"Error: No image files found in {data_dir}")
        return

    labels = [path.parent.name for path in image_paths]

    label_to_id = {label: idx for idx, label in enumerate(set(labels))}
    labels = [label_to_id[label] for label in labels]

    num_classes = len(label_to_id)

    # Split data into train, validation, and test sets
    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(image_paths, labels, test_size=0.15, stratify=labels, random_state=42)
    train_paths, val_paths, train_labels, val_labels = train_test_split(train_val_paths, train_val_labels, test_size=0.1765, stratify=train_val_labels, random_state=42)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Create datasets
    train_dataset = JellyfishDataset(train_paths, train_labels, transform=get_transforms(is_train=True))
    val_dataset = JellyfishDataset(val_paths, val_labels, transform=get_transforms(is_train=False))
    test_dataset = JellyfishDataset(test_paths, test_labels, transform=get_transforms(is_train=False))

    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)

    model = JellyfishModel(num_classes=num_classes)

    trainer = pl.Trainer(
        max_epochs=50,
        accelerator='gpu' if torch.cuda.is_available() else 'cpu',
        devices=1,
        callbacks=[
            EarlyStopping(monitor='val_loss', patience=3, mode='min'),
            ModelCheckpoint(dirpath='./checkpoints', filename='model-{epoch:02d}-{val_loss:.2f}', save_top_k=1, monitor='val_loss', mode='min'),
        ],
        enable_progress_bar=True,
    )

    trainer.fit(model, train_loader, val_loader)

    # Test the model
    test_result = trainer.test(model, test_loader)
    print(f"Test Result: {test_result}")

    # Save the final model
    torch.save(model.state_dict(), 'final_model.pth')

if __name__ == "__main__":
    main()
